gamma: .95
learning_rate: 1e-3
entropy_coefficient: 1e-4
training_episodes: 10000
shared_layers: [128, 64, 32]
dropout: .2